In this project we were tasked with implementing a graph data structure on a given dataset. We found an enticing set on Stanford's SNAP website that had serialized wikipedia article connections. It came as two files, one that stored the article name to index conversion and one that stored the edges between said indices. At first, we were going to make our own implementation of a graph but found that the CS225 provided graph was applicable to our problem. We implemented ShortestPath and PageRank for our algorithms and did a DFS traversal on the data. 

Doing the shortest path algorithm was a big pain but we did it. We ran into some trouble with the test cases. I could test them locally but since we can’t use external libraries it was unusual to test the algorithm but now we are more than 100% sure they work. We worked on a graph implementation but later deleted it since we started using the 225 graph implementation which we felt was a much better choice since there might have been a few edge cases that we could not test/notice. We  decided to test our shortest route algorithm against a fairly complex graph that we found online.
 
In our pagerank implementation we decided to use a more iterative approach. It was kind of unclear as to what implementation was being asked for by the deliverables section of the assignment. Because of this I went for the algorithm that goes through every node and increments its adjacent nodes “weights” in a hashmap by a value depending on the amount of outgoing edges and the total graph size. The values I calculated matched up with the ones from wikipedia’s example and an assortment of other websites. To have the algorithm run properly it was necessary that every node have an incoming edge such that a traversal starting at any point could eventually reach there. If this assumption was not true, we would have to account for the “leaf” nodes and start a new traversal from these nodes. We ran a script to make sure that every point in our dataset had at least one incoming node so that we would not have to add this edge case and add to the complexity of our algorithm. 

Initially we worked on the project assuming a human user would be interacting with the program, so we wrote a command line interface and a ‘nearest match’ suggestion function for when the Start/End point that the user entered could not be found in the dataset. However, we later found out that our project had to run on text file inputs so we converted our command line i/o to file i/o. Using file i/o also meant that we had to choose how the input text file would be formatted and parsed. Ultimately this works as well as, if not better than, the command line interface. 
